{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51c660fa",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation\n",
    "In this phase, I focus on the modeling of various algorithms and subsequently conduct a thorough evaluation to gauge their performance and effectiveness in addressing the problem at hand.\n",
    "\n",
    "\n",
    "To tackle the challenge of class imbalance, I have employed a weight-based model selection approach. By assigning different weights to the classes during model training, we aim to give more emphasis to the minority class, ensuring a more balanced learning process. This strategic use of weights aids in mitigating the impact of class imbalance and contributes to the overall robustness of the model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c021267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StandardScaler, PCA, VectorAssembler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import Evaluator as evaluator\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "from pyspark.ml.tuning import ParamGridBuilder,CrossValidator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aac3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .appName('Bosch Project Train') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233021a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loding the numeric data\n",
    "df_numeric = spark.read.csv(\"pca_transformed.csv\", header=True, inferSchema=True)\n",
    "df_test = spark.read.csv(\"test_numeric.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a2a8f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- PC0: double (nullable = true)\n",
      " |-- PC1: double (nullable = true)\n",
      " |-- PC2: double (nullable = true)\n",
      " |-- PC3: double (nullable = true)\n",
      " |-- PC4: double (nullable = true)\n",
      " |-- PC5: double (nullable = true)\n",
      " |-- PC6: double (nullable = true)\n",
      " |-- PC7: double (nullable = true)\n",
      " |-- PC8: double (nullable = true)\n",
      " |-- PC9: double (nullable = true)\n",
      " |-- PC10: double (nullable = true)\n",
      " |-- PC11: double (nullable = true)\n",
      " |-- PC12: double (nullable = true)\n",
      " |-- PC13: double (nullable = true)\n",
      " |-- PC14: double (nullable = true)\n",
      " |-- PC15: double (nullable = true)\n",
      " |-- PC16: double (nullable = true)\n",
      " |-- PC17: double (nullable = true)\n",
      " |-- PC18: double (nullable = true)\n",
      " |-- PC19: double (nullable = true)\n",
      " |-- PC20: double (nullable = true)\n",
      " |-- PC21: double (nullable = true)\n",
      " |-- PC22: double (nullable = true)\n",
      " |-- PC23: double (nullable = true)\n",
      " |-- PC24: double (nullable = true)\n",
      " |-- PC25: double (nullable = true)\n",
      " |-- PC26: double (nullable = true)\n",
      " |-- PC27: double (nullable = true)\n",
      " |-- PC28: double (nullable = true)\n",
      " |-- PC29: double (nullable = true)\n",
      " |-- Response: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_numeric.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8cec94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding weights to each class\n",
    "df_numeric = df_numeric.withColumn(\"weight\",F.when(df_numeric[\"Response\"]==0,0.5).otherwise(90))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a73ce1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- PC0: double (nullable = true)\n",
      " |-- PC1: double (nullable = true)\n",
      " |-- PC2: double (nullable = true)\n",
      " |-- PC3: double (nullable = true)\n",
      " |-- PC4: double (nullable = true)\n",
      " |-- PC5: double (nullable = true)\n",
      " |-- PC6: double (nullable = true)\n",
      " |-- PC7: double (nullable = true)\n",
      " |-- PC8: double (nullable = true)\n",
      " |-- PC9: double (nullable = true)\n",
      " |-- PC10: double (nullable = true)\n",
      " |-- PC11: double (nullable = true)\n",
      " |-- PC12: double (nullable = true)\n",
      " |-- PC13: double (nullable = true)\n",
      " |-- PC14: double (nullable = true)\n",
      " |-- PC15: double (nullable = true)\n",
      " |-- PC16: double (nullable = true)\n",
      " |-- PC17: double (nullable = true)\n",
      " |-- PC18: double (nullable = true)\n",
      " |-- PC19: double (nullable = true)\n",
      " |-- PC20: double (nullable = true)\n",
      " |-- PC21: double (nullable = true)\n",
      " |-- PC22: double (nullable = true)\n",
      " |-- PC23: double (nullable = true)\n",
      " |-- PC24: double (nullable = true)\n",
      " |-- PC25: double (nullable = true)\n",
      " |-- PC26: double (nullable = true)\n",
      " |-- PC27: double (nullable = true)\n",
      " |-- PC28: double (nullable = true)\n",
      " |-- PC29: double (nullable = true)\n",
      " |-- Response: integer (nullable = true)\n",
      " |-- weight: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_numeric.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f333b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=df_numeric.columns[1:-2], outputCol=\"features\")\n",
    "assembled_data = assembler.transform(df_numeric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5811b86",
   "metadata": {},
   "source": [
    "# Logestic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74b91e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The time taken to train the data is: 152.272 seconds\n"
     ]
    }
   ],
   "source": [
    "# Separate the data based on labels\n",
    "#df_label1 = assembled_data.filter(F.col(\"Response\") == 1)\n",
    "#df_label2 = assembled_data.filter(F.col(\"Response\") == 0)\n",
    "\n",
    "\n",
    "# Perform train-test split for each label\n",
    "#train_label1, test_label1 = df_label1.randomSplit([0.9, 0.1], seed=42)\n",
    "#train_label2, test_label2 = df_label2.randomSplit([0.9, 0.1], seed=42)\n",
    "\n",
    "#train_data = train_label1.union(train_label2)\n",
    "# Concatenate the test sets\n",
    "#test_data = test_label1.union(test_label2)\n",
    "\n",
    "# Create a Logistic Regression model\n",
    "log_reg = LogisticRegression(featuresCol='features', labelCol='Response',weightCol=\"weight\")\n",
    "\n",
    "# Specify parameter grid for tuning\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(log_reg.elasticNetParam, [1, 0, 0.5])\\\n",
    "    .addGrid(log_reg.regParam, [0.0, 0.2, 0.4, 0.6, 0.8, 1])\\\n",
    "    .addGrid(log_reg.maxIter, [10, 15, 20])\\\n",
    "    .build()\n",
    "\n",
    "# Create a CrossValidator\n",
    "evaluator_lr = MulticlassClassificationEvaluator(weightCol=\"weight\",labelCol='Response')\n",
    "crossval = CrossValidator(estimator=log_reg,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator_lr,\n",
    "                          numFolds=3)\n",
    "\n",
    "# Fit the model on the training data\n",
    "start_time = time.time()\n",
    "cvModel = crossval.fit(assembled_data)\n",
    "end_time = time.time()\n",
    "\n",
    "training_time = end_time - start_time\n",
    "print(\"The time taken to train the data is: %0.3f seconds\" % training_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de0da11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Elastic Net Parameter: 1.0\n",
      "Best Regularization Parameter: 0.0\n",
      "Best Max Iterations Parameter: 10\n"
     ]
    }
   ],
   "source": [
    "best_model = cvModel.bestModel\n",
    "\n",
    "# Print or access the best parameters\n",
    "best_elastic_net_param = best_model.getOrDefault(\"elasticNetParam\")\n",
    "best_reg_param = best_model.getOrDefault(\"regParam\")\n",
    "best_max_iter = best_model.getOrDefault(\"maxIter\")\n",
    "\n",
    "print(\"Best Elastic Net Parameter:\", best_elastic_net_param)\n",
    "print(\"Best Regularization Parameter:\", best_reg_param)\n",
    "print(\"Best Max Iterations Parameter:\", best_max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ad11d89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+\n",
      "|Response|prediction| count|\n",
      "+--------+----------+------+\n",
      "|       1|       0.0|  3690|\n",
      "|       0|       0.0|722631|\n",
      "|       1|       1.0|  3189|\n",
      "|       0|       1.0|454237|\n",
      "+--------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(featuresCol='features', labelCol='Response',weightCol=\"weight\",elasticNetParam=1,regParam=0,maxIter=10)\n",
    "model = log_reg.fit(assembled_data)\n",
    "prediction = model.transform(assembled_data)\n",
    "output = prediction.select(\"Response\", \"probability\", \"prediction\")\n",
    "conf_matrix = prediction.groupBy(\"Response\", \"prediction\").count()\n",
    "conf_matrix.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6bd209f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6131546690297842"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\",labelCol='Response',predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = evaluator.evaluate(prediction)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "39f67d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012115476519323112"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = 3189\n",
    "tn = 722631\n",
    "fp = 454237\n",
    "fn = 3690\n",
    "mcc = (tp * tn - fp * fn) / ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))**0.5\n",
    "mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb773c9",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecdc35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"Response\", bootstrap= True, weightCol=\"weight\",seed=22,featureSubsetStrategy=\"log2\")\n",
    "\n",
    "random_forest_paramGrid = ParamGridBuilder()\\\n",
    "               .addGrid(rf.numTrees, [60,100,120])\\\n",
    "               .addGrid(rf.maxDepth, [10,15,20])\\\n",
    "               .build()\n",
    "\n",
    "# Create a CrossValidator\n",
    "rf_evaluator = MulticlassClassificationEvaluator(weightCol=\"weight\",labelCol='Response')\n",
    "crossval = CrossValidator(estimator=rf,\n",
    "                          estimatorParamMaps=random_forest_paramGrid,\n",
    "                          evaluator=rf_evaluator,\n",
    "                          numFolds=2)\n",
    "\n",
    "# Fit the model on the training data\n",
    "start_time = time.time()\n",
    "cvModel = crossval.fit(assembled_data)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2885d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"Response\", bootstrap= True, weightCol=\"weight\",numTrees=100,maxDepth=30, featureSubsetStrategy =\"log2\")\n",
    "model = rf.fit(assembled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ca00e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predic = model.transform(assembled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a46971c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- PC0: double (nullable = true)\n",
      " |-- PC1: double (nullable = true)\n",
      " |-- PC2: double (nullable = true)\n",
      " |-- PC3: double (nullable = true)\n",
      " |-- PC4: double (nullable = true)\n",
      " |-- PC5: double (nullable = true)\n",
      " |-- PC6: double (nullable = true)\n",
      " |-- PC7: double (nullable = true)\n",
      " |-- PC8: double (nullable = true)\n",
      " |-- PC9: double (nullable = true)\n",
      " |-- PC10: double (nullable = true)\n",
      " |-- PC11: double (nullable = true)\n",
      " |-- PC12: double (nullable = true)\n",
      " |-- PC13: double (nullable = true)\n",
      " |-- PC14: double (nullable = true)\n",
      " |-- PC15: double (nullable = true)\n",
      " |-- PC16: double (nullable = true)\n",
      " |-- PC17: double (nullable = true)\n",
      " |-- PC18: double (nullable = true)\n",
      " |-- PC19: double (nullable = true)\n",
      " |-- PC20: double (nullable = true)\n",
      " |-- PC21: double (nullable = true)\n",
      " |-- PC22: double (nullable = true)\n",
      " |-- PC23: double (nullable = true)\n",
      " |-- PC24: double (nullable = true)\n",
      " |-- PC25: double (nullable = true)\n",
      " |-- PC26: double (nullable = true)\n",
      " |-- PC27: double (nullable = true)\n",
      " |-- PC28: double (nullable = true)\n",
      " |-- PC29: double (nullable = true)\n",
      " |-- Response: integer (nullable = true)\n",
      " |-- weight: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predic.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8e7554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+\n",
      "|Response|prediction| count|\n",
      "+--------+----------+------+\n",
      "|       1|       0.0|  3045|\n",
      "|       0|       0.0|943388|\n",
      "|       1|       1.0|  3834|\n",
      "|       0|       1.0|233480|\n",
      "+--------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = predic.groupBy(\"Response\", \"prediction\").count()\n",
    "conf_matrix.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8156ce67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06814953676418936"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = 3834\n",
    "tn = 943388\n",
    "fp = 233480\n",
    "fn = 3045\n",
    "mcc = (tp * tn - fp * fn) / ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))**0.5\n",
    "mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b17b1",
   "metadata": {},
   "source": [
    "# Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7290ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481da4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pca_transformed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5285729f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming df is your DataFrame with features and labels\n",
    "X = df.iloc[:, 1:-1]  # Features\n",
    "y = df.iloc[:, -1]    # Labels\n",
    "\n",
    "# Split the data with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ccbf6288",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-20 12:52:01,935] A new study created in memory with name: no-name-8f144bec-cd48-46ee-bde7-e4bf9b38be0b\n",
      "C:\\Users\\akhil\\AppData\\Local\\Temp\\ipykernel_11860\\1661105430.py:59: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  model.add(Dropout(trial.suggest_uniform(f'dropout{i+1}', 0, 0.8)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189400/189400 [==============================] - 694s 4ms/step - loss: 19.4400 - mcc: 1.4080e-05 - val_loss: 0.3409 - val_mcc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-20 13:03:35,874] Trial 0 finished with value: 1.4079520042287186e-05 and parameters: {'hidden_layers': 8, 'layer1': 8, 'activation1': 'elu', 'layer2': 512, 'dropout2': 0.15616557604249268, 'activation2': 'relu', 'layer3': 64, 'dropout3': 0.2763162500501685, 'activation3': 'elu', 'layer4': 256, 'dropout4': 0.6949797984513861, 'activation4': 'relu', 'layer5': 512, 'dropout5': 0.7773205336868814, 'activation5': 'elu', 'layer6': 512, 'dropout6': 0.292025652342486, 'activation6': 'relu', 'layer7': 64, 'dropout7': 0.07021480764410991, 'activation7': 'elu', 'layer8': 64, 'dropout8': 0.4039501306893736, 'activation8': 'elu', 'optimizer': 'rmsprop'}. Best is trial 0 with value: 1.4079520042287186e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation F1 score: 1.4079520042287186e-05\n",
      "Trial No.=0, HP_Set={'hidden_layers': 8, 'layer1': 8, 'activation1': 'elu', 'layer2': 512, 'dropout2': 0.15616557604249268, 'activation2': 'relu', 'layer3': 64, 'dropout3': 0.2763162500501685, 'activation3': 'elu', 'layer4': 256, 'dropout4': 0.6949797984513861, 'activation4': 'relu', 'layer5': 512, 'dropout5': 0.7773205336868814, 'activation5': 'elu', 'layer6': 512, 'dropout6': 0.292025652342486, 'activation6': 'relu', 'layer7': 64, 'dropout7': 0.07021480764410991, 'activation7': 'elu', 'layer8': 64, 'dropout8': 0.4039501306893736, 'activation8': 'elu', 'optimizer': 'rmsprop'},             Score=1.4079520042287186e-05\n",
      "Best Value =1.4079520042287186e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akhil\\AppData\\Local\\Temp\\ipykernel_11860\\1661105430.py:59: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  model.add(Dropout(trial.suggest_uniform(f'dropout{i+1}', 0, 0.8)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153771/189400 [=======================>......] - ETA: 5:45 - loss: 105.6301 - mcc: 5.3726e-05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-01-20 13:28:30,215] Trial 1 failed with parameters: {'hidden_layers': 10, 'layer1': 8, 'activation1': 'elu', 'layer2': 1024, 'dropout2': 0.6652835216312506, 'activation2': 'relu', 'layer3': 256, 'dropout3': 0.3158502490458037, 'activation3': 'elu', 'layer4': 64, 'dropout4': 0.6787881779742483, 'activation4': 'relu', 'layer5': 1024, 'dropout5': 0.056928539445858566, 'activation5': 'relu', 'layer6': 512, 'dropout6': 0.029581655580786227, 'activation6': 'elu', 'layer7': 512, 'dropout7': 0.1719089228674948, 'activation7': 'relu', 'layer8': 256, 'dropout8': 0.043020760448456846, 'activation8': 'relu', 'layer9': 512, 'dropout9': 0.7627237194312421, 'activation9': 'relu', 'layer10': 512, 'dropout10': 0.5631044770428193, 'activation10': 'relu', 'optimizer': 'adam'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\AppData\\Local\\Temp\\ipykernel_11860\\1661105430.py\", line 72, in objective_func\n",
      "    result = model.fit(X_train, y_train,\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1783, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 831, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\", line 867, in _call\n",
      "    return tracing_compilation.call_function(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py\", line 1264, in _call_flat\n",
      "    return self._inference_function.flat_call(args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\", line 217, in flat_call\n",
      "    flat_outputs = self(*args)\n",
      "                   ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py\", line 252, in __call__\n",
      "    outputs = self._bound_context.call_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 1479, in call_function\n",
      "    outputs = execute.execute(\n",
      "              ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\akhil\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 60, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-01-20 13:28:30,217] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m validation_f1_m\n\u001b[0;32m     84\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39mTPESampler())\n\u001b[1;32m---> 85\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective_func, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,callbacks\u001b[38;5;241m=\u001b[39m[log])\n\u001b[0;32m     86\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial f1 score : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_trial\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[49], line 72\u001b[0m, in \u001b[0;36mobjective_func\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     67\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     68\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[mcc],\n\u001b[0;32m     69\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39mtrial\u001b[38;5;241m.\u001b[39msuggest_categorical(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     70\u001b[0m               [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     71\u001b[0m stop_on_negative_mcc \u001b[38;5;241m=\u001b[39m StopOnNegativeMCC(threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train,\n\u001b[0;32m     73\u001b[0m                 batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     74\u001b[0m                 epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     75\u001b[0m                 validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,class_weight\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m86\u001b[39m},callbacks \u001b[38;5;241m=\u001b[39m [stop_on_negative_mcc]\n\u001b[0;32m     76\u001b[0m                                 )\n\u001b[0;32m     78\u001b[0m validation_f1_m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mamax(result\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmcc\u001b[39m\u001b[38;5;124m'\u001b[39m])        \n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation F1 score:\u001b[39m\u001b[38;5;124m'\u001b[39m, validation_f1_m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[0;32m    869\u001b[0m   )\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    256\u001b[0m     )\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1485\u001b[0m   )\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def mcc(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
    "    false_positives = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
    "    false_negatives = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
    "\n",
    "    numerator = true_positives * true_negatives - false_positives * false_negatives\n",
    "    denominator = K.sqrt((true_positives + false_positives) * (true_positives + false_negatives) * (true_negatives + false_positives) * (true_negatives + false_negatives) + K.epsilon())\n",
    "\n",
    "    mcc_value = numerator / denominator\n",
    "    return mcc_value\n",
    "\n",
    "def log(study, trial):\n",
    "      print(f\"Trial No.={trial.number}, HP_Set={trial.params}, \\\n",
    "            Score={trial.value}\")\n",
    "      print(f\"Best Value ={study.best_value}\")\n",
    "    \n",
    "def objective_func(trial):\n",
    "    \n",
    "    model = Sequential()\n",
    "    hidden_layer_unit_choice = [64, 256, 512, 1024]\n",
    "    hidden_layers = trial.suggest_int('hidden_layers', 5, 15)\n",
    "    model.add(Dense(units=trial.suggest_categorical('layer1', [8, 16]),\n",
    "                 input_shape=((30,)),\n",
    "                 name='dense1'))\n",
    "    model.add(Activation(activation=trial.suggest_categorical(\n",
    "                                                f'activation1',\n",
    "                                                       ['relu',\n",
    "                                                      'elu'])))\n",
    "    for i in range(1, hidden_layers):\n",
    "        model.add(Dense(units=trial.suggest_categorical(f'layer{i+1}',\n",
    "                                              hidden_layer_unit_choice)))\n",
    "        model.add(Dropout(trial.suggest_uniform(f'dropout{i+1}', 0, 0.8)))\n",
    "        \n",
    "        model.add(Activation(activation=trial.suggest_categorical(\n",
    "                                            f'activation{i+1}',\n",
    "                                                       ['relu',\n",
    "                                                      'elu'])))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation(activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  metrics=[mcc],\n",
    "                  optimizer=trial.suggest_categorical('optimizer',\n",
    "                  ['rmsprop', 'adam', 'sgd']))\n",
    "    stop_on_negative_mcc = StopOnNegativeMCC(threshold=0.0)\n",
    "    result = model.fit(X_train, y_train,\n",
    "                    batch_size=4,\n",
    "                    epochs=1,\n",
    "                    validation_split=0.2,class_weight={0:0.5,1:86}\n",
    "                                    )\n",
    "     \n",
    "    validation_f1_m = np.amax(result.history['mcc'])        \n",
    "      \n",
    "      \n",
    "    print('validation mcc :', validation_f1_m)\n",
    "    return validation_f1_m\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "study.optimize(objective_func, n_trials=50,callbacks=[log])\n",
    "best_trial = study.best_trial.value\n",
    "print(f\"Best trial mcc : {best_trial}\")\n",
    "print(\"parameters for best trail are :\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "   print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e703e",
   "metadata": {},
   "source": [
    "#### The training duration for the neural network is excessively long, and the achieved Matthews Correlation Coefficient (MCC) score is notably low, approximately 5 x 10^-5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b48b79",
   "metadata": {},
   "source": [
    "# XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "664f7fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 21:36:06,729 WARNING SparkXGBClassifier: _validate_gpu_params You have enabled GPU in spark local mode. Please make sure your local node has at least 1 GPUs\n",
      "2024-01-20 21:36:07,323 INFO XGBoost-PySpark: _fit Running xgboost-2.0.3 on 1 workers with\n",
      "\tbooster params: {'objective': 'binary:logistic', 'device': 'cuda', 'nthread': 1}\n",
      "\ttrain_call_kwargs_params: {'verbose_eval': True, 'num_boost_round': 100}\n",
      "\tdmatrix_kwargs: {'nthread': 1, 'missing': nan}\n",
      "2024-01-20 21:36:09,011 INFO SparkXGBClassifier: _skip_stage_level_scheduling Stage-level scheduling in xgboost requires spark standalone or local-cluster mode\n",
      "2024-01-20 21:36:17,488 INFO XGBoost-PySpark: _fit Finished xgboost training!\n"
     ]
    }
   ],
   "source": [
    "from xgboost.spark import SparkXGBClassifier\n",
    "\n",
    "regressor = SparkXGBClassifier(features_col=\"features\", label_col=\"Response\", device=\"cuda\",weight_col=\"weight\")\n",
    "\n",
    "# train and return the model\n",
    "model = regressor.fit(assembled_data)\n",
    "\n",
    "# predict on test data\n",
    "predict_df = model.transform(assembled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c41be8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------+\n",
      "|Response|prediction| count|\n",
      "+--------+----------+------+\n",
      "|       1|       0.0|  1998|\n",
      "|       0|       0.0|855091|\n",
      "|       1|       1.0|  4881|\n",
      "|       0|       1.0|321777|\n",
      "+--------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = predict_df.groupBy(\"Response\", \"prediction\").count()\n",
    "conf_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcf9451b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07416270967845472"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = 4881\n",
    "tn = 855091\n",
    "fp = 321777\n",
    "fn = 1998\n",
    "mcc = (tp * tn - fp * fn) / ((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))**0.5\n",
    "mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c89a4f",
   "metadata": {},
   "source": [
    "#### Distributed XGBoost implemented with PySpark demonstrates superior performance compared to other classification algorithms, boasting an impressive Matthews Correlation Coefficient (MCC) of 0.075 with higher True Positive Rate ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8761280",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
